# 1.大模型预训练 - Pre-Training
# 2.Transformer架构
# 3.大模型发布
# 4.大模型微调 - Fine-Tuning
>## 4.1.什么是微调
>>    微调就是在预训练好的通用大模型基础上，
    用特定领域的小数据进一步训练，使其适配具体任务的技术。
>## 4.2.微调的分类
>>### 4.2.1.魔搭社区的约定
>>> base模型和instruct模型
>>### 4.2.2.按微调策略分类
>>>#### 1).全参数微调 - Full Fine-Tuning
>>>#### 2).参数高效微调 - Parameter-Efficient Fine-Tuning, PEFT
>>>>##### (1).LoRA: Low-Rank Adaptation
>>>>##### (2).QLoRA：量化+LoRA
>>>>##### (3).适配器: Adapter
>>>>#####	   。。。。。。
>>### 4.2.3.按数据利用方式分类
>>>#### 1).监督微调 - Supervised Fine-Tuning, SFT
>>>#### 2).无监督/自监督微调
>>>#### 3).强化学习微调（RLHF、DPO、PPO）
>>> *** 对比:预训练和微调； 可以看一下 K-Means算法
>## 4.3.学习微调的原因
>>### 4.3.1.现有技术的局限性
>>### 4.3.2.软硬件技术发展的必然
>>### 4.3.3.差异化竞争的需要
        最后再强调一点，在预训练基础上，即使用采用和预训练同样的
    数据格式、和预训练同样的训练方法继续训练，但是如果只有较
    小的数据量，只是为了增强特定领域的能力，则应该将其纳入微调范畴。
##
##
##
##
# 微调  第二讲
## 1.微调工作有几种干法
>### 1.1.微调的第一种干法是在云上用云服务商提供的工具做预训练
>### 1.2.第二种方式就是下载微调工具到本地训练
>### 1.3.第三种方式则就是通过自主可控
> 
## 2.微调数据集准备
>### 2.1.Alpaca数据格式
>### 2.2.shareGPT数据格式
>### 2.3.百炼约定数据集格式
>### 2.4.硅基流动约定数据集格式
>### 2.5.LlamaFactory约定数据集格式
>### 2.6.MiniMind工程中的数据集格式
> 
## 3.从开源数据集的流行程度看发展风向
>### 3.1.自我认知数据集
>### 3.2.魔搭通用SFT数据集
>### 3.3.Evol-instruction-66k  编码方向的数据   Structure
>### 3.4.中文基于满血DeepSeek-R1蒸馏数据集-110k-SFT版本
>### 3.5.两个法律， 两个医疗数据集， 专业性比较强的数据集
>### 3.6.搜索 “微调"，  图像处理，
#
#
# 第三讲 LoRA微调
## 1.矩阵秩的概念
    矩阵的秩是其行向量或列向量的极大线性无关组中向量的个数****
## 2.三元一次方程组求解
    1x + 2y + 3z = 10
    2x + 4y + 6z = 20
	3x + 6y + 9z = 30
## 3.LoRA微调论文
    LORA: LOW-RANK ADAPTATION OF LARGE LANGUAGE MODELS
    https://arxiv.org/pdf/2106.09685
## 4.动画演示参数计算
    提示词：
    做一个网页，对比展示lora参数计算
## 5.LoRA微调的参数计算
    阿里云
    硅基流动
    Llama-Factory
## 6.对比词向量模型和FFN层
    词向量模型：
        https://zhuanlan.zhihu.com/p/577136561
    前馈层（FFN）例子：
        https://zhuanlan.zhihu.com/p/685943779

#
#
#
#
